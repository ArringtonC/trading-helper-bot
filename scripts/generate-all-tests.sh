#!/bin/bash

# Auto-generate test files for all services without existing tests
# Usage: ./scripts/generate-all-tests.sh

set -e

echo "🚀 Starting automated test generation for all services..."
echo "📊 Current test coverage analysis:"

# Count current test files
CURRENT_TESTS=$(find src -name "*.test.ts" -o -name "*.test.tsx" | wc -l)
TOTAL_FILES=$(find src -name "*.ts" -o -name "*.tsx" | grep -v ".test." | grep -v ".spec." | wc -l)

echo "   📁 Current test files: $CURRENT_TESTS"
echo "   📁 Total source files: $TOTAL_FILES"
echo "   📊 Current coverage: $(echo "scale=1; $CURRENT_TESTS * 100 / $TOTAL_FILES" | bc)%"
echo ""

# Make the generator script executable
chmod +x scripts/generate-service-test.js

echo "🔍 Phase 1: Generating Service Tests..."
echo "============================================"

# Find all services without tests and generate them
SERVICE_COUNT=0
find src/services -name "*.ts" -not -name "*.test.ts" -not -name "*.spec.ts" | while read -r file; do
  testfile="${file%.ts}.test.ts"
  
  if [ ! -f "$testfile" ]; then
    echo "📝 Generating test for: $(basename "$file")"
    
    # Generate the test file
    node scripts/generate-service-test.js "$file"
    
    # Increment counter
    SERVICE_COUNT=$((SERVICE_COUNT + 1))
    
    echo "   ✅ Created: $testfile"
    echo ""
  else
    echo "   ⏭️  Skipping $(basename "$file") - test already exists"
  fi
done

echo ""
echo "🧩 Phase 2: Generating Component Tests..."
echo "==========================================="

# Component test generator (basic template)
COMPONENT_COUNT=0
find src/components -name "*.tsx" -not -name "*.test.tsx" -not -name "*.spec.tsx" | head -10 | while read -r file; do
  testfile="${file%.tsx}.test.tsx"
  
  if [ ! -f "$testfile" ]; then
    component_name=$(basename "$file" .tsx)
    
    echo "📝 Generating basic test for: $component_name"
    
    # Generate basic component test
    cat > "$testfile" << EOF
import { render, screen } from '@testing-library/react';
import $component_name from './$component_name';

describe('$component_name', () => {
  it('should render without crashing', () => {
    render(<$component_name />);
    // TODO: Add specific assertions
    expect(true).toBe(true);
  });
  
  it('should handle props correctly', () => {
    // TODO: Add props testing
    expect(true).toBe(true);
  });
  
  it('should be accessible', () => {
    // TODO: Add accessibility tests
    expect(true).toBe(true);
  });
  
  // GENERATED BY: scripts/generate-all-tests.sh
  // DATE: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
  // SOURCE: $file
  // TODO: Expand with specific test cases
});
EOF
    
    COMPONENT_COUNT=$((COMPONENT_COUNT + 1))
    echo "   ✅ Created: $testfile"
    echo ""
  fi
done

echo ""
echo "🛠️  Phase 3: Generating Utility Tests..."
echo "========================================="

# Utility test generator
UTILITY_COUNT=0
find src/utils -name "*.ts" -not -name "*.test.ts" -not -name "*.spec.ts" | head -10 | while read -r file; do
  testfile="${file%.ts}.test.ts"
  
  if [ ! -f "$testfile" ]; then
    util_name=$(basename "$file" .ts)
    
    echo "📝 Generating basic test for utility: $util_name"
    
    # Generate basic utility test
    cat > "$testfile" << EOF
// Import the utility functions
// import { functionName } from './$util_name';

describe('$util_name', () => {
  describe('Utility Functions', () => {
    it('should export expected functions', () => {
      // TODO: Test that expected functions are exported
      expect(true).toBe(true);
    });
    
    it('should handle valid inputs', () => {
      // TODO: Test with valid inputs
      expect(true).toBe(true);
    });
    
    it('should handle invalid inputs gracefully', () => {
      // TODO: Test error handling
      expect(true).toBe(true);
    });
  });
  
  // GENERATED BY: scripts/generate-all-tests.sh
  // DATE: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
  // SOURCE: $file
  // TODO: Add specific utility function tests
});
EOF
    
    UTILITY_COUNT=$((UTILITY_COUNT + 1))
    echo "   ✅ Created: $testfile"
    echo ""
  fi
done

echo ""
echo "📊 Test Generation Summary"
echo "=========================="

# Final count
NEW_TESTS=$(find src -name "*.test.ts" -o -name "*.test.tsx" | wc -l)
TOTAL_FILES_AFTER=$(find src -name "*.ts" -o -name "*.tsx" | grep -v ".test." | grep -v ".spec." | wc -l)

echo "   📈 Tests before: $CURRENT_TESTS"
echo "   📈 Tests after: $NEW_TESTS"
echo "   📈 New tests created: $((NEW_TESTS - CURRENT_TESTS))"
echo "   📊 New coverage: $(echo "scale=1; $NEW_TESTS * 100 / $TOTAL_FILES_AFTER" | bc)%"
echo ""

echo "🎯 Next Steps for the Async Bot:"
echo "================================="
echo "1. 🔍 Review all generated test files"
echo "2. 📝 Fill in TODO comments with actual test cases"
echo "3. 🧪 Add mock data and realistic test scenarios"
echo "4. 🔧 Fix any TypeScript compilation errors"
echo "5. ▶️  Run test suite: npm test"
echo "6. 📊 Generate coverage report: npm test -- --coverage"
echo ""

echo "🚨 High Priority Services to Focus On:"
echo "======================================"
echo "   🔥 AnalyticsDataService.ts (core analytics)"
echo "   🔥 VolatilityAnalysisService.ts (risk calculation)"
echo "   🔥 IBKRAPIClient.ts (external integration)"
echo "   🔥 RiskService.ts (risk management)"
echo "   🔥 StreamingService.ts (real-time data)"
echo ""

echo "🎉 Automated test generation complete!"
echo "🤖 The async bot can now start filling in the test implementations."

# Create a summary file for the bot
cat > scripts/test-generation-summary.md << EOF
# Test Generation Summary - $(date)

## Generated Test Files
- Services: $SERVICE_COUNT new test files
- Components: $COMPONENT_COUNT new test files  
- Utilities: $UTILITY_COUNT new test files

## Coverage Improvement
- Before: $CURRENT_TESTS tests ($(echo "scale=1; $CURRENT_TESTS * 100 / $TOTAL_FILES" | bc)%)
- After: $NEW_TESTS tests ($(echo "scale=1; $NEW_TESTS * 100 / $TOTAL_FILES_AFTER" | bc)%)

## Next Actions for Bot
1. Implement actual test logic in generated files
2. Add proper mocking for external dependencies
3. Create realistic test data
4. Add integration tests
5. Set up coverage reporting

## High Priority Files
- All service tests (business logic critical)
- Large component tests (UI stability)
- Utility function tests (shared functionality)
EOF

echo "📄 Summary saved to: scripts/test-generation-summary.md" 